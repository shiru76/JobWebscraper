{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb3a75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "cols = ['title', 'company', 'location', 'salary', 'days_since_posted', 'link', 'night_shift', 'sql', 'excel', 'tableau', \n",
    "        'power_bi', 'python', 'r', 'career_level', 'qualification', 'years_of_experience', 'job_type', 'specialization', \n",
    "        'subspecialty', 'registration_no', 'company size', 'ave_process_time', 'industry', 'benefits_and_others']\n",
    "extracted_data = []\n",
    "job_info = []\n",
    "    \n",
    "# Additional information section\n",
    "def job_addtl_info(job_post_soup_prettify):\n",
    "    job_post_div = job_post_soup_prettify.findAll('div', attrs={'class': 'z1s6m00 _1hbhsw6r pmwfa50 pmwfa57'})\n",
    "\n",
    "    for job_addtl_desc in job_post_div:\n",
    "        skills = job_addtl_desc.text\n",
    "\n",
    "        if 'career level' in skills.lower():\n",
    "            pattern = re.compile('Career Level', re.IGNORECASE)\n",
    "            job_info[13] = pattern.sub('', skills).strip()             \n",
    "        elif 'qualification' in skills.lower():\n",
    "            pattern = re.compile('Qualification', re.IGNORECASE)\n",
    "            job_info[14] = pattern.sub('', skills).strip()             \n",
    "        elif 'years of experience' in skills.lower():\n",
    "            pattern = re.compile('Years of Experience', re.IGNORECASE)\n",
    "            job_info[15] = pattern.sub('', skills).strip()             \n",
    "        elif 'job type' in skills.lower():\n",
    "            pattern = re.compile('Job Type', re.IGNORECASE)\n",
    "            job_info[16] = pattern.sub('', skills).strip()             \n",
    "        elif 'job specializations' in skills.lower():\n",
    "            pattern = re.compile('Job Specializations', re.IGNORECASE)\n",
    "            specializations = pattern.sub('', skills).split(',')\n",
    "            job_info[17] = specializations[0].strip()\n",
    "            job_info[18] = specializations[1].strip()    \n",
    "        elif 'registration no.' in skills.lower():\n",
    "            pattern = re.compile('registration no.', re.IGNORECASE)\n",
    "            job_info[19] = pattern.sub('', skills).strip()\n",
    "        elif 'company size' in skills.lower():\n",
    "            pattern = re.compile('company size', re.IGNORECASE)\n",
    "            job_info[20] = pattern.sub('', skills).strip()\n",
    "        elif 'average processing time' in skills.lower():\n",
    "            pattern = re.compile('average processing time', re.IGNORECASE)\n",
    "            job_info[21] = pattern.sub('', skills).strip()\n",
    "        elif 'industry' in skills.lower():\n",
    "            pattern = re.compile('industry', re.IGNORECASE)\n",
    "            job_info[22] = pattern.sub('', skills).strip()\n",
    "        elif 'benefits & others' in skills.lower():\n",
    "            pattern = re.compile('benefits & others', re.IGNORECASE)\n",
    "            job_info[23] = pattern.sub('', skills).strip()\n",
    "            whitespace = re.compile(r'\\s+')\n",
    "            job_info[23] = whitespace.sub(' ', job_info[23]).strip()            \n",
    "\n",
    "# Job description section containing skills\n",
    "def job_skills_desc(job_post_soup_prettify):\n",
    "    job_post_div = job_post_soup_prettify.findAll('div', attrs={'data-automation': 'jobDescription'})\n",
    "\n",
    "    for job_desc in job_post_div:\n",
    "        description = job_desc.text\n",
    "        \n",
    "        if 'night shift' in description.lower():\n",
    "            job_info[6] = 'Yes'\n",
    "        else:\n",
    "            job_info[6] = 'No'\n",
    "\n",
    "        if 'sql' in description.lower():\n",
    "            job_info[7] = 'Yes'\n",
    "        else:\n",
    "            job_info[7] = 'No'\n",
    "\n",
    "        if 'excel' in description.lower():\n",
    "            job_info[8] = 'Yes'\n",
    "        else:\n",
    "            job_info[8] = 'No'\n",
    "\n",
    "        if 'tableau' in description.lower():\n",
    "            job_info[9] = 'Yes'\n",
    "        else:\n",
    "            job_info[9] = 'No'\n",
    "\n",
    "        if 'power bi' in description.lower():\n",
    "            job_info[10] = 'Yes'\n",
    "        else:\n",
    "            job_info[10] = 'No'\n",
    "\n",
    "        if 'python' in description.lower():\n",
    "            job_info[11] = 'Yes'\n",
    "        else:\n",
    "            job_info[11] = 'No'\n",
    "\n",
    "        if re.search(\"[^a-zA-Z]R[^a-zA-Z]\", description):\n",
    "            job_info[12] = 'Yes'\n",
    "        else:\n",
    "            job_info[12] = 'No'\n",
    "                        \n",
    "# Page containing the job list\n",
    "def jobs_extract(job_list):  \n",
    "    for job_post in job_list:        \n",
    "        global job_info \n",
    "        job_info = ['none'] * len(cols)\n",
    "        \n",
    "        # Job Title\n",
    "        job_info[0] = job_post.find('div', attrs={'class': 'z1s6m00 l3gun70 l3gun74 l3gun72'}).text.strip()\n",
    "        print(\"\\n\" + job_info[0])\n",
    "        \n",
    "        # Company Name\n",
    "        # sometimes data-automation attribute is not working\n",
    "#         company.append(job_post.find('a', attrs={'data-automation': 'jobCardCompanyLink'}).text.strip()) \n",
    "        job_info[1] = job_post.find('span', attrs={'class': 'z1s6m00 _17dyj7u1 _1hbhsw64u _1hbhsw60 _1hbhsw6r'}).text.strip()\n",
    "        \n",
    "        # Location and Salary\n",
    "#         location = job_post.find('a', attrs={'data-automation': 'jobCardLocationLink'}).text\n",
    "        loc_salary_info = [\n",
    "            location_salary.getText(strip=True) for location_salary in job_post.findAll('span', attrs={'class': 'z1s6m00 _1hbhsw64u y44q7i0 y44q7i3 y44q7i21 y44q7ih'})\n",
    "        ]\n",
    "        job_info[2] = loc_salary_info[0]\n",
    "        print(job_info[2])\n",
    "        \n",
    "        if len(loc_salary_info) == 2:\n",
    "            job_info[3] = loc_salary_info[1]\n",
    "            print(job_info[3])\n",
    "        else:\n",
    "            print(\"none\")\n",
    "        \n",
    "        # Days since posted\n",
    "        job_info[4] = job_post.find('time', attrs={'class': 'z1s6m00 _1hbhsw64u'}).text.strip()\n",
    "        \n",
    "        # Additional details\n",
    "        details = job_post.find('a', attrs={'class': 'jdlu994 jdlu996 jdlu999 y44q7i2 z1s6m00 z1s6m0f _1hbhsw6h'}, href=True)\n",
    "\n",
    "        # Job link\n",
    "        job_post_url = 'https://www.jobstreet.com.ph' + str(details['href'])\n",
    "        job_post_page = requests.get(job_post_url, headers=headers)\n",
    "        job_info[5] = job_post_url\n",
    "        \n",
    "        job_post_soup = BeautifulSoup(job_post_page.content,'html.parser')\n",
    "        job_post_soup_prettify = BeautifulSoup(job_post_soup.prettify(), 'html.parser')\n",
    "\n",
    "        # Job skills and other description\n",
    "        job_skills_desc(job_post_soup_prettify)\n",
    "        \n",
    "        # Job additional information\n",
    "        job_addtl_info(job_post_soup_prettify)\n",
    "                                                        \n",
    "        # Save all additional information\n",
    "        extracted_data.append(job_info)\n",
    "        \n",
    "# Saving the extracted data in excel\n",
    "def jobs_save():\n",
    "    # Save all information\n",
    "    all_jobs_list = {} \n",
    "    \n",
    "    # Transpose the data using numpy\n",
    "    transposed_data = np.array(extracted_data).T.tolist()\n",
    "\n",
    "    # Save the data using pandas\n",
    "    for job in range(len(cols)):\n",
    "        all_jobs_list[cols[job]] = transposed_data[job]\n",
    "\n",
    "    filename = \"jobstreet_dataset.xls\"\n",
    "    jobs = pd.DataFrame(all_jobs_list)\n",
    "    jobs.to_excel(filename, index=False)    \n",
    "\n",
    "# Job searching \n",
    "def jobs_search():\n",
    "    page_number = 1 # Current page number of webscraper; Initial is 1\n",
    "    total_num_pages = 1 # Number of pages to be extracted; Initial is 1\n",
    "    jobs_per_page = 30 # Number of jobs per page\n",
    "\n",
    "    while page_number <= total_num_pages:\n",
    "        url = 'https://www.jobstreet.com.ph/en/job-search/data-analyst-jobs/' + str(page_number)\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "        soup_prettify = BeautifulSoup(soup.prettify(), \"html.parser\")\n",
    "\n",
    "        job_list = soup_prettify.findAll('div', attrs={'class': 'z1s6m00 _1hbhsw69e _1hbhsw68e _1hbhsw672 _1hbhsw67e'})\n",
    "#         job_list = soup_prettify.findAll('div', attrs={'data-automation': 'jobListing'})\n",
    "\n",
    "        # Get the number of jobs\n",
    "        if page_number == 1:\n",
    "            job_search_bar = soup_prettify.find('div', attrs={'data-automation': 'searchResultBar'}).text.split('of')\n",
    "            job_numbers = int(job_search_bar[1].replace('jobs', '').replace(',', '').strip())\n",
    "            total_num_pages = math.ceil(job_numbers/jobs_per_page)\n",
    "            print(total_num_pages)\n",
    "        \n",
    "        print(\"Page number: \" + str(page_number))\n",
    "        page_number += 1\n",
    "            \n",
    "        jobs_extract(job_list)\n",
    "    \n",
    "    jobs_save()\n",
    "                \n",
    "jobs_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "window.scroll_flag = true\n",
    "window.scroll_exit = false\n",
    "window.scroll_delay = 100\n",
    "\n",
    "$(\".output_scroll\").each(function() {\n",
    "    $(this)[0].scrollTop = $(this)[0].scrollHeight;\n",
    "});\n",
    "\n",
    "function callScrollToBottom() {\n",
    "    setTimeout(scrollToBottom, window.scroll_delay);\n",
    "}\n",
    "\n",
    "function scrollToBottom() {\n",
    "    if (window.scroll_exit) {\n",
    "        return;\n",
    "    }\n",
    "    if (!window.scroll_flag) {\n",
    "        callScrollToBottom();\n",
    "        return;\n",
    "    };\n",
    "    \n",
    "    $(\".output_scroll\").each(function() {\n",
    "        if (!$(this).attr('scroll_checkbox')){\n",
    "            window.scroll_flag = true;\n",
    "            $(this).attr('scroll_checkbox',true);\n",
    "            var div = document.createElement('div');\n",
    "            var checkbox = document.createElement('input');\n",
    "            checkbox.type = \"checkbox\";\n",
    "            checkbox.onclick = function(){window.scroll_flag = checkbox.checked}\n",
    "            checkbox.checked = \"checked\"\n",
    "            div.append(\"Auto-Scroll-To-Bottom: \");\n",
    "            div.append(checkbox);\n",
    "            $(this).parent().before(div);\n",
    "        }\n",
    "        \n",
    "        $(this)[0].scrollTop = $(this)[0].scrollHeight;\n",
    "    });\n",
    "    callScrollToBottom();\n",
    "}\n",
    "scrollToBottom();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

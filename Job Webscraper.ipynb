{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb3a75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "cols = ['title', 'company', 'location', 'salary', 'days_since_posted', 'link', 'career_level', 'qualification',\n",
    "        'years_of_experience', 'job_type', 'specialization', 'subspecialty', 'night_shift', 'sql', 'excel', 'tableau', \n",
    "        'power_bi', 'python', 'r']\n",
    "title = []\n",
    "company = []\n",
    "location = []\n",
    "salary = []\n",
    "days_since_posted = []\n",
    "link = []\n",
    "career_level = []\n",
    "qualification = []\n",
    "years_of_experience = []\n",
    "job_type = []\n",
    "specialization = []\n",
    "subspecialty = []\n",
    "night_shift = []\n",
    "sql = []\n",
    "excel = []\n",
    "tableau = []\n",
    "power_bi = []\n",
    "python = []\n",
    "r = []\n",
    "extracted_info = []\n",
    "    \n",
    "def jobs_extract(job_list):    \n",
    "    for job_post in job_list:        \n",
    "        job_info = ['none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none',\n",
    "                    'none', 'none', 'none', 'none', 'none', 'none', 'none']\n",
    "        \n",
    "        # Job Title\n",
    "        job_info[0] = job_post.find('div', attrs={'class': 'z1s6m00 l3gun70 l3gun74 l3gun72'}).text.strip()\n",
    "        print(\"\\n\" + job_info[0])\n",
    "        \n",
    "        # Company Name\n",
    "        # sometimes data-automation attribute is not working\n",
    "#         company.append(job_post.find('a', attrs={'data-automation': 'jobCardCompanyLink'}).text.strip()) \n",
    "        job_info[1] = job_post.find('span', attrs={'class': 'z1s6m00 _17dyj7u1 _1hbhsw64u _1hbhsw60 _1hbhsw6r'}).text.strip()\n",
    "        \n",
    "        # Location and Salary\n",
    "#         location = job_post.find('a', attrs={'data-automation': 'jobCardLocationLink'}).text\n",
    "        loc_salary_info = [\n",
    "            location_salary.getText(strip=True) for location_salary in job_post.findAll('span', attrs={'class': 'z1s6m00 _1hbhsw64u y44q7i0 y44q7i3 y44q7i21 y44q7ih'})\n",
    "        ]\n",
    "        job_info[2] = loc_salary_info[0]\n",
    "        print(job_info[2])\n",
    "        \n",
    "        if len(loc_salary_info) == 2:\n",
    "            job_info[3] = loc_salary_info[1]\n",
    "            print(job_info[3])\n",
    "        else:\n",
    "            print(\"none\")\n",
    "        \n",
    "        # Days since posted\n",
    "        job_info[4] = job_post.find('time', attrs={'class': 'z1s6m00 _1hbhsw64u'}).text.strip()\n",
    "        \n",
    "        # Full details\n",
    "        details = job_post.find('a', attrs={'class': 'jdlu994 jdlu996 jdlu999 y44q7i2 z1s6m00 z1s6m0f _1hbhsw6h'}, href=True)\n",
    "\n",
    "        job_post_url = 'https://www.jobstreet.com.ph' + str(details['href'])\n",
    "        job_post_page = requests.get(job_post_url, headers=headers)\n",
    "        job_info[5] = job_post_url\n",
    "        \n",
    "        job_post_soup1 = BeautifulSoup(job_post_page.content,'html.parser')\n",
    "        job_post_soup2 = BeautifulSoup(job_post_soup1.prettify(), 'html.parser')\n",
    "\n",
    "        job_post_div = job_post_soup2.findAll('div', attrs={'data-automation': 'jobDescription'})\n",
    "        \n",
    "        for job_desc in job_post_div:\n",
    "            description = job_desc.text\n",
    "\n",
    "            if 'night shift' in description.lower():\n",
    "                job_info[12] = 'Yes'\n",
    "            else:\n",
    "                job_info[12] = 'No'\n",
    "                \n",
    "            if 'sql' in description.lower():\n",
    "                job_info[13] = 'Yes'\n",
    "            else:\n",
    "                job_info[13] = 'No'\n",
    "                \n",
    "            if 'excel' in description.lower():\n",
    "                job_info[14] = 'Yes'\n",
    "            else:\n",
    "                job_info[14] = 'No'\n",
    "                \n",
    "            if 'tableau' in description.lower():\n",
    "                job_info[15] = 'Yes'\n",
    "            else:\n",
    "                job_info[15] = 'No'\n",
    "                \n",
    "            if 'power bi' in description.lower():\n",
    "                job_info[16] = 'Yes'\n",
    "            else:\n",
    "                job_info[16] = 'No'\n",
    "\n",
    "            if 'python' in description.lower():\n",
    "                job_info[17] = 'Yes'\n",
    "            else:\n",
    "                job_info[17] = 'No'\n",
    "\n",
    "            if re.search(\"[^a-zA-Z]R[^a-zA-Z]\", description):\n",
    "                job_info[18] = 'Yes'\n",
    "            else:\n",
    "                job_info[18] = 'No'\n",
    "                                \n",
    "        # Additional job information\n",
    "        job_post_div2 = job_post_soup2.findAll('div', attrs={'class': 'z1s6m00 _1hbhsw6r pmwfa50 pmwfa57'})\n",
    "        \n",
    "        for job_addtl_desc in job_post_div2:\n",
    "            skills2 = job_addtl_desc.text\n",
    "\n",
    "            if 'career level' in skills2.lower():\n",
    "                pattern = re.compile('Career Level', re.IGNORECASE)\n",
    "                job_info[6] = pattern.sub('', skills2).strip()             \n",
    "            elif 'qualification' in skills2.lower():\n",
    "                pattern = re.compile('Qualification', re.IGNORECASE)\n",
    "                job_info[7] = pattern.sub('', skills2).strip()             \n",
    "            elif 'years of experience' in skills2.lower():\n",
    "                pattern = re.compile('Years of Experience', re.IGNORECASE)\n",
    "                job_info[8] = pattern.sub('', skills2).strip()             \n",
    "            elif 'job type' in skills2.lower():\n",
    "                pattern = re.compile('Job Type', re.IGNORECASE)\n",
    "                job_info[9] = pattern.sub('', skills2).strip()             \n",
    "            elif 'job specializations' in skills2.lower():\n",
    "                pattern = re.compile('Job Specializations', re.IGNORECASE)\n",
    "                specializations = pattern.sub('', skills2).split(',')\n",
    "                job_info[10] = specializations[0].strip()\n",
    "                job_info[11] = specializations[1].strip()\n",
    "                \n",
    "        #Save all additional information\n",
    "        title.append(job_info[0])\n",
    "        company.append(job_info[1])\n",
    "        location.append(job_info[2])\n",
    "        salary.append(job_info[3])\n",
    "        days_since_posted.append(job_info[4])\n",
    "        link.append(job_info[5])\n",
    "        career_level.append(job_info[6])\n",
    "        qualification.append(job_info[7])\n",
    "        years_of_experience.append(job_info[8])\n",
    "        job_type.append(job_info[9])\n",
    "        specialization.append(job_info[10])\n",
    "        subspecialty.append(job_info[11])\n",
    "        night_shift.append(job_info[12])\n",
    "        sql.append(job_info[13])\n",
    "        excel.append(job_info[14])\n",
    "        tableau.append(job_info[15])\n",
    "        power_bi.append(job_info[16])\n",
    "        python.append(job_info[17])\n",
    "        r.append(job_info[18])\n",
    "        \n",
    "        print(\"python? \" + job_info[17])\n",
    "        print(\"r? \" + job_info[17])\n",
    "    \n",
    "def jobs_save():\n",
    "    #Save all information\n",
    "    all_jobs_list = {}\n",
    "\n",
    "    print(\"Length of columns\")\n",
    "    print(len(title))\n",
    "    print(len(company))\n",
    "    print(len(location))\n",
    "    print(len(salary))\n",
    "    print(len(days_since_posted))\n",
    "    print(len(link))\n",
    "    print(len(career_level))\n",
    "    print(len(qualification))\n",
    "    print(len(years_of_experience))\n",
    "    print(len(job_type))\n",
    "    print(len(specialization))\n",
    "    print(len(subspecialty))\n",
    "    print(len(night_shift))\n",
    "    print(len(sql))\n",
    "    print(len(excel))\n",
    "    print(len(tableau))\n",
    "    print(len(power_bi))\n",
    "    print(len(python))\n",
    "    print(len(r))\n",
    "      \n",
    "    extracted_info.append(title)\n",
    "    extracted_info.append(company)\n",
    "    extracted_info.append(location)\n",
    "    extracted_info.append(salary)\n",
    "    extracted_info.append(days_since_posted)\n",
    "    extracted_info.append(link)\n",
    "    extracted_info.append(career_level)\n",
    "    extracted_info.append(qualification)\n",
    "    extracted_info.append(years_of_experience)\n",
    "    extracted_info.append(job_type)\n",
    "    extracted_info.append(specialization)\n",
    "    extracted_info.append(subspecialty)\n",
    "    extracted_info.append(night_shift)\n",
    "    extracted_info.append(sql)\n",
    "    extracted_info.append(excel)\n",
    "    extracted_info.append(tableau)\n",
    "    extracted_info.append(power_bi)\n",
    "    extracted_info.append(python)    \n",
    "    extracted_info.append(r)    \n",
    "\n",
    "    for j in range(len(cols)):\n",
    "        all_jobs_list[cols[j]] = extracted_info[j]\n",
    "\n",
    "    filename = \"jobstreet_dataset.xls\"\n",
    "    jobs = pd.DataFrame(all_jobs_list)\n",
    "    jobs.to_excel(filename, index=False)    \n",
    "                                            \n",
    "def jobs_search():\n",
    "    page_number = 1\n",
    "    total_num_pages = 1 #Initial number of pages to be extracted\n",
    "    jobs_per_page = 30 #Number of jobs per page\n",
    "\n",
    "    while page_number <= total_num_pages:\n",
    "        url = 'https://www.jobstreet.com.ph/en/job-search/data-analyst-jobs-in-philippines/' + str(page_number)\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup1 = BeautifulSoup(page.content,\"html.parser\")\n",
    "        soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
    "\n",
    "        job_list = soup2.findAll('div', attrs={'class': 'z1s6m00 _1hbhsw69e _1hbhsw68e _1hbhsw672 _1hbhsw67e'})\n",
    "#         job_list = soup2.findAll('div', attrs={'data-automation': 'jobListing'})\n",
    "\n",
    "        # No. of jobs\n",
    "        if 1 == page_number:\n",
    "            job_search_bar = soup2.find('div', attrs={'data-automation': 'searchResultBar'}).text.split('of')\n",
    "            job_numbers = int(job_search_bar[1].replace('jobs', '').replace(',', '').strip())\n",
    "            total_num_pages = math.ceil(job_numbers/jobs_per_page)\n",
    "            print(total_num_pages)\n",
    "        \n",
    "        print(\"Page number: \" + str(page_number))\n",
    "        page_number += 1\n",
    "            \n",
    "        jobs_extract(job_list)\n",
    "    \n",
    "    jobs_save()\n",
    "                \n",
    "jobs_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "window.scroll_flag = true\n",
    "window.scroll_exit = false\n",
    "window.scroll_delay = 100\n",
    "\n",
    "$(\".output_scroll\").each(function() {\n",
    "    $(this)[0].scrollTop = $(this)[0].scrollHeight;\n",
    "});\n",
    "\n",
    "function callScrollToBottom() {\n",
    "    setTimeout(scrollToBottom, window.scroll_delay);\n",
    "}\n",
    "\n",
    "function scrollToBottom() {\n",
    "    if (window.scroll_exit) {\n",
    "        return;\n",
    "    }\n",
    "    if (!window.scroll_flag) {\n",
    "        callScrollToBottom();\n",
    "        return;\n",
    "    };\n",
    "    \n",
    "    $(\".output_scroll\").each(function() {\n",
    "        if (!$(this).attr('scroll_checkbox')){\n",
    "            window.scroll_flag = true;\n",
    "            $(this).attr('scroll_checkbox',true);\n",
    "            var div = document.createElement('div');\n",
    "            var checkbox = document.createElement('input');\n",
    "            checkbox.type = \"checkbox\";\n",
    "            checkbox.onclick = function(){window.scroll_flag = checkbox.checked}\n",
    "            checkbox.checked = \"checked\"\n",
    "            div.append(\"Auto-Scroll-To-Bottom: \");\n",
    "            div.append(checkbox);\n",
    "            $(this).parent().before(div);\n",
    "        }\n",
    "        \n",
    "        $(this)[0].scrollTop = $(this)[0].scrollHeight;\n",
    "    });\n",
    "    callScrollToBottom();\n",
    "}\n",
    "scrollToBottom();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
